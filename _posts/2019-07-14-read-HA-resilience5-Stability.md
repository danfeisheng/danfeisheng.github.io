---
layout: post
title: "读《高可用可伸缩微服务架构》感"
date: "2019-07-21 21:59"
author: "Danfei"
---
2019-07-21 21:59

读《高可用可伸缩微服务架构》感

第四章 微服务稳定性保证的常用手段

对于整个分布式系统来说，它的故障概率是各个环节故障概率的乘积。因此，我们在系统设计时应该拥抱故障，应该考虑如何减轻故障的概率，如何快速从故障中恢复。

我们一般从以下两点来考虑系统的稳定性：

1. 高可用：当前服务依赖的下游系统性能降低或失败时，该服务该怎么响应，是快速失败还是增加重试？大促时如何应对瞬间涌入的流量。
2. 高并发：底层服务如何保证服务的吞吐量？如何提高消费者的处理速度？

** 高可用 **

限流：每个系统都有自己的最大服务能力，即在达到某个临界点之前，系统都可以正常提供服务，为了保证系统在面临瞬时的流量时仍然可以对外提供服务，我们需要
使用限流技术。

常见的限流算法有计数器算法，漏桶算法和令牌桶算法。

1. 技术器算法，维护一个counter，在规定单位时间内counter不能超过最大值，每隔固定的时间就将counter置零，如果这个counter大于阈值了，那么系统就开始拒绝请求
以保护系统的负载

2. 漏桶算法，维护一个固定容量的桶，这个桶按照固定速度漏水（处理请求），如果桶满了，就会忽略后面的请求，缺点是在瞬间流量过来时，会拒绝后面的请求流量。
一般会使用一个队列实现“漏斗”的效果，当请求过多时，队列中的请求开始积压，当队列满了之后，就开始拒绝请求。

3. 令牌桶算法，随着时间的流逝，系统会按照指定的速度往桶里添加token，每来一个新请求，就从桶里拿走一个token，如果没有token可拿就拒绝服务。这种算法的好处是
便于控制系统的处理速度，甚至可以通弄过统计信息实时优化令牌桶的大小。

从理论上来说，令牌桶算法和漏桶算法的不同之处在于处理瞬时到达的大流量的不同，令牌桶算法由于在令牌桶里攒了很多令牌，因此在大流量到达的瞬间可以一次性
将队列中所有的请求都处理完，然后按照恒定的速度处理请求，漏桶算法则一直有一个恒等的阈值。（令牌桶算法会把瞬间大流量都接受了，然后以恒定的速度处理，
漏桶算法有一个最大请求排队数的阈值）

** 超时与重试 **

在微服务系统中，如果上游应用没有使用合理的设置超时和重试机制，则会造成请求响应变慢，慢请求会积压并耗尽系统资源，从而导致无法为新来的请求提供服务，
导致系统崩溃。超时重试机制应该和限流，断路器配合使用，最终实现微服务系统的稳定性。

** 高并发 **

我们常常使用消息队列来削峰填谷，这里也有风险点，消息队列的消费会不会阻塞，阻塞后会不会导致业务消息延后？有两个理论可以知道我们处理这些问题，
阿姆达尔定律和局部性原理。

	+ 阿姆达尔定律：一个计算机科学界的经验法则，它代表了处理器平行运算之后效率的提升能力。在并行计算中用多处理器的应用加速受限于程序所需的串行时间
	百分比。比如，程序的50%是串行的，其他一半可以并行，那么最大的加速比就是2.不管多少个处理器并行，这个加速比不可能提高。在这种情况下，改进串行算法
	可能比多核处理器并行更有效。
	+ 局部性原理：局部性分为时间局部性和空间局部性，所以时间局部性指的是如果一个信息正在被访问，那么短期内它很有可能会被再次访问。所谓空间局部性指的
	是如果一个信息正在被访问，那么与它存储位置相近的信息也可能马上会被访问。
	
在上述两个理论的指导下，** 有几种常见的高并发策略：**

	+ ** 异步：提高业务过程中可异步部分的占比，提高异步部分的执行效率 **
	+ ** 缓存： 将频繁访问的数据存储在离业务处理逻辑更近的地方 **
	+ ** 池化： 对于创建起来比较消耗资源的对象进行缓存 **
	
异步：

按照异步操作出现的位置，可以分为两类：在JVM内部，使用异步线程池或异步回调机制；在JVM外部，可以使用消息队列，Redis队列等中间件。

线程池的使用和监控

Java中可以通过Executors和ThreadPoolExecutor的方式创建线程，通过Executors可以快速创建四种常见的线程池，但这种方式在实际使用中并不推荐，因为这种方式创建
出来的线程池的可控性较差，更推荐使用ThreadPoolExecutor提供的方法。参考阿里巴巴Java开发规范：

	+ 线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式去创建，这样的处理方式让写的人员更明确线程池的运行机制，规避资源耗尽的风险。
	Executors返回的线程池对象弊端如下：
		
		- FixedThreadPool和SingleThreadPool：允许的请求队列长度为Integer.MAX_VALUE,可能会堆积大量的请求，从而导致OOM
		- CacheThreadPool和ScheduledThreadPool：允许创建线程数量为Integer.MAX_VALUE，可能创建大量的线程，从而导致OOM
		
线程池的corePoolSize是真个线程池中最关键的参数，设置的太小会导致线程池的吞吐量不足，因为新提交的任务需要排队或被handler处理（取决于拒绝策略）；设置
的太大可能会耗尽计算机的CPU和内存资源。线程池满了之后，再有新的线程提交，就会执行设定的拒绝策略，我们可以实现自定义的拒绝策略，从而可以打印出告警日志。
最后，线上应用在运行过程中，我们希望能够通过日志监控异步线程池的运行状况，在发生异常时及时处理。** 自定义线程池组件一种思路是： **

	1. 使用有界队列的固定数量线程池
	2. 拒绝策略是将任务丢弃，但需要记录错误日志
	3. 使用一个调度线程池对业务线程池进行监控
	
异步回调机制

现在业界流行的响应式编程就是异步回调模式，异步回调跟同步调用的不同在于，请求发起方不需要等待服务方的响应返回，可以先去做别的业务，接口请求返回后，
会自动调用预先埋设的回调函数，进行后续的业务处理。可以看出，异步回调模式改变了我们写代码的思考模型。

** 消息队列 **

线程池和异步回调是代码级别的异步策略，消息队列则是系统架构层面的异步策略。消息队列的应用场景很广泛，例如削峰填谷，抗住流量洪峰，然后将耗时的业务逻辑
按照自己的速度处理，可以保护下游业务系统的稳定性。典型的应用是优惠券发放和电商秒杀系统。

** 缓存 **

CPU的发展速度远远快于内存的发展速度，为了平衡这种差距，计算机系统引入了缓存的概念，告诉缓存中的数据是内存数据在CPU中的缓存，内存数据是硬盘数据的缓存。

在分布式系统中，缓存无处不在，从缓存静态资源的CDN，到缓存HTTP请求的Nginx缓存，从浏览器或App客户端的缓存，到服务端到数据存储的缓存。

我们一般采用CacheAcide模式来使用缓存

	+ 读数据：先尝试从缓存中读取数据，如果读到则直接返回，如果没有读到，则从DB中读取数据，并存入缓存，并将该数据返回给客户端。
	+ 写数据：在DB中的数据发生变更（更新或删除）时，需要先操作DB，再将缓存中的数据失效。** 注意这里不是更新缓存中的数据，而是直接失效**。
	由下一次读取数据的进程重新写入缓存。这么设计的原因是：如果右A和B两个进程在并发的更新同一条数据，则可能的执行顺序为A更新DB，B更新DB，B更新缓存，
	A更新缓存，则可以看到B的更新结果被A覆盖了。
	
在分布式系统中使用缓存时，需要处理好缓存穿透，缓存雪崩，大value缓存检测，热点缓存等问题。

	+ 缓存穿透：一般的缓存系统都是按照key去缓存查询的，如果不存在对应的value，则应该去后端系统查询（比如DB）。如果key对应的value一定不存在，并且对该
	key的并发量很大，就会对后端系统造成很大的压力。这就叫缓存穿透。
	+ 缓存学霸：当缓存服务器重启或大量集中在某一个时间段失效，在失效的时候，也会给后端系统（比如DB）带来很大的压力。
	+ 热点缓存：缓存中的某些key对应的value存储在集群中的一台机器中，使得又有的流量涌向统一机器，成为瓶颈。针对热点缓存，可以考虑加入本地缓存来解决。
	不过本地缓存一般都不大，因此需要严格控制热点key的数据，我们可以通过一个RateLimiter来统计过去一段时间内某个key被访问的次数，如果达到了阈值，就将
	该key设置为热点key。
	
从高可用和高并发两个方面保障服务的稳定性

要保障高可用，首先要做到微服务中不能存在单点，需要服务冗余，这个可以通过自动化运维，服务发现，负载均衡等技术来实现。在一个微服务系统中，某个节点出现
问题是一种高概率事件，我们系统应该面向失败设计，因此我们论述了隔离，降级，熔断的技术。在遇到瞬间流量的时候，有些服务节点可能会抗不住压力导致服务质量
降低，这时就有可能导致故障传递，也就是雪崩效应，为了处理这种情况，可以采用限流和重试。

要实现高并发，一般有两个思路：异步和缓存。异步的策略可以按照如下方法来实施：梳理业务逻辑，将可以异步的流程都异步化，可以保护下游的系统不受大流量的冲击。
在微服务系统中，不同的存储系统的访问速度也不相同，为了屏蔽这种差距，可以使用缓存将常用的数据尽量前置，可以保护后端系统。

